{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "# Writing SQW for BIFROST"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1",
   "metadata": {},
   "source": [
    "**Idea for determining position in pixel block:**\n",
    "\n",
    "- Compute an upper bound size for each (Q,E,irun,idet,ien) bin.\n",
    "- For each event, compute an index based on that upper bound.\n",
    "- `group` or `groupby` in that index. This only retains indices where we have data and orders the data by the index. If the index is computed right, that is the order in a pixel block.\n",
    "- `sum` the bins.\n",
    "- Write the result into the pixel block.\n",
    "\n",
    "The extra index event coord should not be too large, we should be able to fit that into memory.\n",
    "\n",
    "If we can make `groupby` lazy in its groups, we can stream the data to file.\n",
    "\n",
    "Or we process the events in arbitrary chunks.\n",
    "For each chunk, compute the index, group, sum.\n",
    "Write to file by: if index out of bounds, grow file and fill with 0s. Then add the new value onto the existing one. That way, we accumulate events directly in the file.\n",
    "Might be quite slow because of somewhat random access to file and many read+writes and because it needs tight loop (-> not Python?)\n",
    "**Maybe not** this would require knowing all index values that can contribute up front top do the grouping."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipp as sc\n",
    "import sciline\n",
    "from scippneutron.io import sqw\n",
    "from pathlib import Path\n",
    "import scippnexus as snx\n",
    "import numpy as np\n",
    "import dataclasses\n",
    "\n",
    "from ess import bifrost\n",
    "from ess.bifrost.data import (\n",
    "    simulated_elastic_incoherent_with_phonon,\n",
    "    tof_lookup_table_simulation\n",
    ")\n",
    "from ess.spectroscopy.types import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_det = 3\n",
    "n_angle = 5\n",
    "\n",
    "bin_sizes = {'u1': 6, 'u2': 7, 'u3': 8, 'u4': 9}\n",
    "\n",
    "out_file = Path(\"bifrost-simulated.sqw\")\n",
    "\n",
    "# Q projections\n",
    "u = sc.vector([1, 0, 0], unit=\"1/angstrom\")\n",
    "v = sc.vector([0, 1, 0], unit=\"1/angstrom\")\n",
    "w = sc.cross(u, v)  # must be orthogonal to u and v for now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "with snx.File(simulated_elastic_incoherent_with_phonon()) as f:\n",
    "    detector_names = list(f['entry/instrument'][snx.NXdetector])\n",
    "detector_names = detector_names[:n_det]\n",
    "\n",
    "workflow = bifrost.BifrostSimulationWorkflow(detector_names)\n",
    "workflow[Filename[SampleRun]] = simulated_elastic_incoherent_with_phonon()\n",
    "workflow[TimeOfFlightLookupTable] = sc.io.load_hdf5(tof_lookup_table_simulation())\n",
    "workflow[PreopenNeXusFile] = PreopenNeXusFile(True)\n",
    "scheduler = sciline.scheduler.NaiveScheduler()\n",
    "\n",
    "data = workflow.compute(EnergyData[SampleRun], scheduler=scheduler)\n",
    "\n",
    "data = data['a3', :n_angle].flatten(['triplet', 'tube', 'length'], 'detector')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "settings = sc.DataArray(\n",
    "    sc.arange('s', data.sizes['a3'] * data.sizes['a4'], unit=None).fold('s', sizes={'a3': data.sizes['a3'],\n",
    "                                                                                    'a4': data.sizes['a4']}),\n",
    "    coords={\n",
    "        'a3': data.coords['a3'],\n",
    "        'a4': data.coords['a4'],\n",
    "    }\n",
    ").flatten(to='setting')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def project_onto(direction, vec):\n",
    "    return sc.dot(direction / sc.norm(direction), vec)\n",
    "\n",
    "\n",
    "aux = (data\n",
    "       .flatten(['a3', 'a4'], 'setting')\n",
    "       # Split into two calls because of https://github.com/scipp/scipp/issues/3766\n",
    "       .transform_coords(\n",
    "    u1=lambda sample_table_momentum_transfer: project_onto(u, sample_table_momentum_transfer),\n",
    "    u2=lambda sample_table_momentum_transfer: project_onto(v, sample_table_momentum_transfer),\n",
    "    u3=lambda sample_table_momentum_transfer: project_onto(w, sample_table_momentum_transfer),\n",
    "    keep_inputs=False,\n",
    ").transform_coords(u4=\"energy_transfer\", keep_inputs=False)\n",
    "       .bins.drop_coords(['incident_energy', 'incident_wavelength', 'lab_momentum_transfer'])\n",
    "       .drop_coords(['a3', 'a4', 'secondary_flight_time'])\n",
    "       )\n",
    "binned = (aux\n",
    "          .bins.assign_coords({\n",
    "    'setting': sc.bins_like(aux, settings.data),\n",
    "    'detector_number': sc.bins_like(aux, aux.coords.pop('detector_number')),\n",
    "})\n",
    "          .bins.concat()\n",
    "          .bin(bin_sizes)\n",
    "          )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def coord_range(da: sc.DataArray, coord: str) -> sc.Variable:\n",
    "    assert sc.islinspace(da.coords[coord])\n",
    "    return sc.array(dims=[coord], values=[da.coords[coord][0].value, da.coords[coord][-1].value],\n",
    "                    unit=da.coords[coord].unit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = sqw.SqwIXSample(\n",
    "    name=\"Vibranium\",\n",
    "    lattice_spacing=sc.vector([2.86, 2.86, 2.86], unit=\"angstrom\"),\n",
    "    lattice_angle=sc.vector([90.0, 90.0, 90.0], unit=\"deg\"),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "dnd_metadata = sqw.SqwDndMetadata(\n",
    "    axes=sqw.SqwLineAxes(\n",
    "        title=\"My Axes\",\n",
    "        label=[\"u1\", \"u2\", \"u3\", \"u4\"],\n",
    "        img_scales=[\n",
    "            sc.scalar(1.0, unit=\"1/angstrom\"),\n",
    "            sc.scalar(1.0, unit=\"1/angstrom\"),\n",
    "            sc.scalar(1.0, unit=\"1/angstrom\"),\n",
    "            sc.scalar(1.0, unit=\"meV\"),\n",
    "        ],\n",
    "        img_range=[\n",
    "            coord_range(binned, name)\n",
    "            for name in [\"u1\", \"u2\", \"u3\", \"u4\"]\n",
    "        ],\n",
    "        n_bins_all_dims=sc.array(dims=[\"axis\"], values=[binned.sizes[f'u{i}'] for i in range(1, 5)], unit=None),\n",
    "        single_bin_defines_iax=sc.array(dims=[\"axis\"], values=[True] * 4),\n",
    "        dax=sc.arange(\"axis\", 4, unit=None),\n",
    "        offset=[\n",
    "            sc.scalar(0.0, unit=\"1/angstrom\"),\n",
    "            sc.scalar(0.0, unit=\"1/angstrom\"),\n",
    "            sc.scalar(0.0, unit=\"1/angstrom\"),\n",
    "            sc.scalar(0.0, unit=\"meV\"),\n",
    "        ],\n",
    "        changes_aspect_ratio=True,\n",
    "    ),\n",
    "    proj=sqw.SqwLineProj(\n",
    "        title=\"My Projection\",\n",
    "        lattice_spacing=sample.lattice_spacing,\n",
    "        lattice_angle=sample.lattice_angle,\n",
    "        offset=[\n",
    "            sc.scalar(0.0, unit=\"1/angstrom\"),\n",
    "            sc.scalar(0.0, unit=\"1/angstrom\"),\n",
    "            sc.scalar(0.0, unit=\"1/angstrom\"),\n",
    "            sc.scalar(0.0, unit=\"meV\"),\n",
    "        ],\n",
    "        label=[\"u1\", \"u2\", \"u3\", \"u4\"],\n",
    "        u=u,\n",
    "        v=v,\n",
    "        w=None,\n",
    "        non_orthogonal=False,\n",
    "        type=\"aaa\",\n",
    "    ),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": [
    "dnd_metadata.axes.img_range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {},
   "outputs": [],
   "source": [
    "instrument = sqw.SqwIXNullInstrument(\n",
    "    name=\"BIFROST\",\n",
    "    source=sqw.SqwIXSource(\n",
    "        name=\"ESS\",\n",
    "        target_name=\"Tungsten wheel\",\n",
    "        frequency=sc.scalar(14, unit=\"Hz\"),\n",
    "    ),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {},
   "outputs": [],
   "source": [
    "en = binned.coords['u4'].broadcast(sizes={'detector': data.sizes['detector'], 'u4': len(binned.coords['u4'])}).rename(\n",
    "    u4='energy_transfer')\n",
    "experiment_template = sqw.SqwIXExperiment(\n",
    "    run_id=0,\n",
    "    efix=data.coords['final_energy'],\n",
    "    emode=sqw.EnergyMode.indirect,\n",
    "    en=en,\n",
    "    psi=sc.scalar(0.0, unit=\"rad\"),\n",
    "    u=u,\n",
    "    v=v,\n",
    "    omega=sc.scalar(0.0, unit=\"rad\"),\n",
    "    dpsi=sc.scalar(0.0, unit=\"rad\"),\n",
    "    gl=sc.scalar(0.0, unit=\"rad\"),\n",
    "    gs=sc.scalar(0.0, unit=\"rad\"),\n",
    ")\n",
    "assert np.unique(data.coords['a4'].values).size == 1\n",
    "experiments = [\n",
    "    dataclasses.replace(experiment_template, run_id=i, psi=a3)\n",
    "    for i, a3 in enumerate(data.coords['a3'], 1)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {},
   "outputs": [],
   "source": [
    "binned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO add 0 observations\n",
    "#  we lose some bins in the above binning processes, e.g., here, idet is only a subset of all detector numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15",
   "metadata": {},
   "outputs": [],
   "source": [
    "observations = binned.copy().drop_coords(['sample_position', 'source_position'])\n",
    "observations = observations.bins.assign_coords(\n",
    "    {\n",
    "        'idet': observations.bins.coords.pop('detector_number').to(dtype='float32') + sc.index(1),\n",
    "        'irun': observations.bins.coords.pop('setting').to(dtype='float32') + sc.index(1),\n",
    "        # +1 because of 1-based indexing\n",
    "    }\n",
    ")\n",
    "observations = observations.assign_coords(\n",
    "    {\n",
    "        f'u{i}': sc.midpoints(observations.coords.pop(f'u{i}')).to(dtype='float32', copy=False)\n",
    "        for i in range(1, 5)\n",
    "    }\n",
    ")\n",
    "observations.coords['ien'] = sc.arange('u4', 1, 1 + observations.sizes['u4'], dtype='float32', unit=None)\n",
    "observations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16",
   "metadata": {},
   "outputs": [],
   "source": [
    "buffer = None\n",
    "\n",
    "\n",
    "def get_buffer(n: int):\n",
    "    global buffer\n",
    "    if buffer is None or buffer.shape[0] < n:\n",
    "        buffer = np.empty((n, 9), dtype=np.float32)\n",
    "        return buffer\n",
    "    return buffer[:n]\n",
    "\n",
    "\n",
    "buffers = []\n",
    "# transpose to match fortran layout. But horace plots look the same, does this actually matter?\n",
    "flat = observations.transpose(['u4', 'u3', 'u2', 'u1']).flatten(to='u')\n",
    "for obs_bin in observations.flatten(to='u'):\n",
    "    h = obs_bin.group('idet', 'irun').hist()\n",
    "    n = h.sizes['idet'] * h.sizes['irun']\n",
    "    h = h.flatten(to='obs')\n",
    "    buf = get_buffer(n)\n",
    "    buf[:, 0] = h.coords['u1'].values\n",
    "    buf[:, 1] = h.coords['u2'].values\n",
    "    buf[:, 2] = h.coords['u3'].values\n",
    "    buf[:, 3] = h.coords['u4'].values\n",
    "    buf[:, 4] = h.coords['irun'].values\n",
    "    buf[:, 5] = h.coords['idet'].values\n",
    "    buf[:, 6] = h.coords['ien'].values\n",
    "    buf[:, 7] = h.values\n",
    "    buf[:, 8] = sc.stddevs(h).values\n",
    "    buffers.append(buf.copy())\n",
    "\n",
    "pix_buffer = np.concat(buffers, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17",
   "metadata": {},
   "outputs": [],
   "source": [
    "bin_sizes = sc.array(dims=['u'], values=[buf.shape[0] for buf in buffers], unit=None)\n",
    "bin_sizes = bin_sizes.fold(dim='u', sizes=observations.sizes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18",
   "metadata": {},
   "outputs": [],
   "source": [
    "builder = sqw.Sqw.build(out_file, title=\"Simulated data with phonon\").add_default_instrument(\n",
    "    instrument).add_default_sample(sample)\n",
    "builder = builder.add_dnd_data(dnd_metadata, data=observations.hist().data, counts=bin_sizes)\n",
    "builder = builder.add_pixel_data(pix_buffer, experiments=experiments)\n",
    "builder.create()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19",
   "metadata": {},
   "outputs": [],
   "source": [
    "with sqw.Sqw.open(out_file) as f:\n",
    "    print(f.data_block_names())\n",
    "    d = f.read_data_block('data', \"nd_data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20",
   "metadata": {},
   "outputs": [],
   "source": [
    "d[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21",
   "metadata": {},
   "outputs": [],
   "source": [
    "binned.hist().data['u1', 3]['u2', 6]['u3', 1]['u4', 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO The dim order is reversed.\n",
    "# Seems wrong, I thought we handled transposition properly now?!\n",
    "d[0][0][1][6][3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23",
   "metadata": {},
   "outputs": [],
   "source": [
    "d[0][3][6][1][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.nonzero(d[0] == 127.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25",
   "metadata": {},
   "outputs": [],
   "source": [
    "binned.hist().sum('u2').sum('u4').transpose(['u3', 'u1']).plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26",
   "metadata": {},
   "source": [
    "### Build pix data using group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Revert all indices to 0-based for faster index arithmetic\n",
    "binned_indices = observations.copy().bins.assign_coords(\n",
    "    **{f'u{i}': sc.bins_like(observations, sc.arange(f'u{i}', observations.sizes[f'u{i}'], unit=None, dtype='float32'))\n",
    "       for i in range(1, 5)},\n",
    "    ien=sc.bins_like(observations, observations.coords['ien'] - sc.index(1)),\n",
    "    irun=observations.bins.coords['irun'] - sc.index(1),\n",
    "    idet=observations.bins.coords['idet'] - sc.index(1),\n",
    ")\n",
    "binned_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_u1 = sc.index(binned_indices.sizes['u1'])\n",
    "n_u2 = sc.index(binned_indices.sizes['u2'])\n",
    "n_u3 = sc.index(binned_indices.sizes['u3'])\n",
    "n_u4 = sc.index(binned_indices.sizes['u4'])\n",
    "n_idet = binned_indices.bins.coords['idet'].max() + sc.index(1)\n",
    "n_irun = binned_indices.bins.coords['irun'].max() + sc.index(1)\n",
    "n_ien = binned_indices.bins.coords['ien'].max() + sc.index(1)\n",
    "\n",
    "i_u1 = binned_indices.bins.coords['u1']\n",
    "i_u2 = binned_indices.bins.coords['u2']\n",
    "i_u3 = binned_indices.bins.coords['u3']\n",
    "i_u4 = binned_indices.bins.coords['u4']\n",
    "idet = binned_indices.bins.coords['idet']\n",
    "irun = binned_indices.bins.coords['irun']\n",
    "ien = binned_indices.bins.coords['ien']\n",
    "\n",
    "out_index = i_u4.to(dtype='int64')\n",
    "for i, n in ((i_u3, n_u3), (i_u2, n_u2), (i_u1, n_u1), (idet, n_idet), (irun, n_irun), (ien, n_ien)):\n",
    "    out_index *= n.to(dtype='int64')\n",
    "    out_index += i.to(dtype='int64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO the data is shorter than when using the custom loop! (A bunch of u4 might be missing)\n",
    "\n",
    "for_grouping = observations.bins.assign_coords(pix_index=out_index)\n",
    "for_grouping = for_grouping.bins.assign_coords({f'u{i}': sc.bins_like(for_grouping, for_grouping.coords.pop(f'u{i}')) for i in range(1, 5)})\n",
    "for_grouping.bins.coords['ien'] = sc.bins_like(for_grouping, for_grouping.coords.pop('ien'))\n",
    "\n",
    "grouped = for_grouping.bins.concat().group('pix_index').drop_coords('pix_index')\n",
    "hist = grouped.bins.sum()\n",
    "# indices in `observations` are 1-based\n",
    "hist = hist.assign_coords({name: grouped.bins.coords.pop(name).bins.min() for name in list(grouped.bins.coords.keys())})\n",
    "hist = hist.assign_coords({})\n",
    "hist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30",
   "metadata": {},
   "outputs": [],
   "source": [
    "hist.group('u3', 'u1').bins.sum().plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31",
   "metadata": {},
   "outputs": [],
   "source": [
    "buffer = np.c_[*(hist.coords[name].values for name in ('u1', 'u2', 'u3', 'u4', 'irun', 'idet', 'ien')), hist.values, sc.stddevs(hist).values]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32",
   "metadata": {},
   "outputs": [],
   "source": [
    "dnd = hist.group('u4', 'u3', 'u2', 'u1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33",
   "metadata": {},
   "outputs": [],
   "source": [
    "builder = sqw.Sqw.build(out_file, title=\"Simulated data with phonon (index method\").add_default_instrument(instrument).add_default_sample(sample)\n",
    "builder = builder.add_dnd_data(dnd_metadata, data=dnd.bins.sum().data, counts=dnd.bins.size())\n",
    "builder = builder.add_pixel_data(buffer, experiments=experiments)\n",
    "builder.create()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34",
   "metadata": {},
   "outputs": [],
   "source": [
    "dnd.bins.sum().data"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
