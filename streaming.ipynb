{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import NewType\n",
    "from dataclasses import dataclass\n",
    "from collections.abc import Callable\n",
    "\n",
    "import scipp as sc\n",
    "import sciline\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "from ess import bifrost\n",
    "from ess.bifrost.data import (\n",
    "    simulated_elastic_incoherent_with_phonon,\n",
    "    tof_lookup_table_simulation\n",
    ")\n",
    "from ess.spectroscopy.types import *\n",
    "import scippnexus as snx\n",
    "from ess.reduce.streaming import StreamProcessor,Accumulator,EternalAccumulator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib widget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass(frozen=True, kw_only=True, slots=True)\n",
    "class CutAxis:\n",
    "    output: str\n",
    "    fn: Callable[[...], sc.Variable]\n",
    "    bins: sc.Variable\n",
    "\n",
    "    @classmethod\n",
    "    def from_q_vector(cls, output: str, vec: sc.Variable, bins: sc.Variable):\n",
    "        vec = vec / sc.norm(vec)\n",
    "        return cls(\n",
    "            output=output,\n",
    "            fn=lambda sample_table_momentum_transfer: sc.dot(vec, sample_table_momentum_transfer),\n",
    "            bins=bins\n",
    "        )\n",
    "\n",
    "CutAxis1 = NewType('CutAxis1', CutAxis)\n",
    "CutAxis2 = NewType('CutAxis2', CutAxis)\n",
    "\n",
    "class CutData(sciline.Scope[RunType, sc.DataArray], sc.DataArray): ...\n",
    "\n",
    "def cut(data: EnergyData[RunType], *, axis_1: CutAxis1, axis_2: CutAxis2) -> CutData[RunType]:\n",
    "    new_coords = {axis_1.output, axis_2.output}\n",
    "    projected = data.bins.concat().transform_coords(new_coords, graph={axis_1.output: axis_1.fn, axis_2.output: axis_2.fn},keep_inputs=False)\n",
    "    projected = projected.drop_coords(list(set(projected.coords.keys()) - new_coords))\n",
    "    return CutData[RunType](projected.hist({axis_2.output: axis_2.bins, axis_1.output: axis_1.bins}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "fname = simulated_elastic_incoherent_with_phonon()\n",
    "with snx.File(fname) as f:\n",
    "    detector_names = list(f['entry/instrument'][snx.NXdetector])\n",
    "detector_names = detector_names[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "workflow = bifrost.BifrostWorkflow(detector_names)\n",
    "workflow[Filename[SampleRun]] = simulated_elastic_incoherent_with_phonon()\n",
    "workflow[TimeOfFlightLookupTableFilename] = tof_lookup_table_simulation()\n",
    "workflow[PreopenNeXusFile] = PreopenNeXusFile(True)\n",
    "\n",
    "workflow.insert(cut)\n",
    "\n",
    "# workflow[CutAxis1] = CutAxis.from_q_vector(\n",
    "#     output=\"Qx\",\n",
    "#     vec=sc.vector([1, 0, 0]),\n",
    "#     bins=sc.linspace('Qx', -3.0, 3.0, 300, unit='1/Å')\n",
    "# )\n",
    "# workflow[CutAxis2] = CutAxis.from_q_vector(\n",
    "#     output=\"Qz\",\n",
    "#     vec=sc.vector([0, 0, 1]),\n",
    "#     bins=sc.linspace('Qz', -3.0, 3.0, 300, unit='1/Å')\n",
    "# )\n",
    "\n",
    "workflow[CutAxis1] = CutAxis(\n",
    "    output=\"|Q|\",\n",
    "    fn=lambda sample_table_momentum_transfer: sc.norm(sample_table_momentum_transfer),\n",
    "    bins=sc.linspace('|Q|', 0.9, 3.0, 300, unit='1/Å')\n",
    ")\n",
    "workflow[CutAxis2] = CutAxis(\n",
    "    output=\"E\",\n",
    "    fn=lambda energy_transfer: energy_transfer,\n",
    "    bins=sc.linspace('E', -0.1, 0.1, 300, unit='meV')\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "workflow.visualize(CutData[SampleRun], graph_attr={\"rankdir\": \"LR\"}, compact=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "scheduler = sciline.scheduler.NaiveScheduler()\n",
    "results = workflow.compute([NeXusData[snx.NXdetector, SampleRun], InstrumentAngles[SampleRun]],\n",
    "                           scheduler=scheduler)\n",
    "base_data = results[NeXusData[snx.NXdetector, SampleRun]]\n",
    "angles = results[InstrumentAngles[SampleRun]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "angles['a3']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is similar to `group_by_rotation` but preserves the event_time_zero coord and dim.\n",
    "# The elements of `angle_groups` look like NeXusData.\n",
    "# For simplicity, it assumes that there is only one a4 value.\n",
    "a3 = sc.lookup(angles['a3'], 'time')\n",
    "a4 = sc.lookup(angles['a4'], 'time')\n",
    "graph = {\n",
    "    'a3': lambda event_time_zero: a3[event_time_zero],\n",
    "    'a4': lambda event_time_zero: a4[event_time_zero],\n",
    "}\n",
    "d = base_data.bins.assign_coords({'event_time_zero': sc.bins_like(base_data.data, base_data.coords['event_time_zero'])})\n",
    "grouped = d.transform_coords(('a3', 'a4'), graph=graph).group('a3', 'a4')\n",
    "angle_groups = [grouped['a3', a3]['a4', 0].group('event_time_zero') for a3 in grouped.coords['a3']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from copy import deepcopy\n",
    "\n",
    "\n",
    "class BinAccumulator(Accumulator[sc.DataArray]):\n",
    "    def __init__(self, **kwargs: Any) -> None:\n",
    "        super().__init__(preprocess=None, **kwargs)\n",
    "        self._value = None\n",
    "\n",
    "    @property\n",
    "    def is_empty(self) -> bool:\n",
    "        return self._value is None\n",
    "\n",
    "    def _get_value(self):\n",
    "        return deepcopy(self._value)\n",
    "\n",
    "    def _do_push(self, value) -> None:\n",
    "        if self._value is None:\n",
    "            self._value = deepcopy(value)\n",
    "        else:\n",
    "            self._value.bins.concatenate(value, out=self._value)\n",
    "\n",
    "    def clear(self) -> None:\n",
    "        \"\"\"Clear the accumulated value.\"\"\"\n",
    "        self._value = None\n",
    "\n",
    "\n",
    "sp = StreamProcessor(\n",
    "    workflow,\n",
    "    dynamic_keys=(NeXusData[snx.NXdetector, SampleRun],),\n",
    "    context_keys=(InstrumentAngles[SampleRun],),\n",
    "    target_keys=(CutData[SampleRun],),\n",
    "    accumulators={\n",
    "        # DataGroupedByRotation[SampleRun]: BinAccumulator(),\n",
    "        CutData[SampleRun]: EternalAccumulator(),\n",
    "    },\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": [
    "times = []\n",
    "for group in angle_groups:\n",
    "    step_angles = sc.DataGroup(a3=sc.DataArray(group.coords['a3']), a4=sc.DataArray(group.coords['a4']))\n",
    "    events = group.drop_coords(['a3', 'a4'])  # NeXusData does not have these coords\n",
    "\n",
    "    start = time.time()\n",
    "    sp.set_context({InstrumentAngles[SampleRun]: step_angles})\n",
    "    sp.accumulate({NeXusData[snx.NXdetector, SampleRun]: events})\n",
    "    end = time.time()\n",
    "    times.append(end-start)\n",
    "\n",
    "print(f\"Sum: {sum(times):.3f}s  Mean: {sum(times)/len(times):.3f}s [{min(times):.3f}s, {max(times):.3f}s]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(times)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = sp.finalize()\n",
    "data = results[CutData[SampleRun]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.plot(norm='log')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
